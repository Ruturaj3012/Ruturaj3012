{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc4d73b",
   "metadata": {},
   "source": [
    "1. Data Wrangling, I\n",
    "Perform the following operations using Python on any open source dataset (e.g., data.csv)\n",
    "1. Import all the required Python Libraries.\n",
    "2. Locate an open source data from the web (e.g., https://www.kaggle.com). Provide a clear\n",
    " description of the data and its source (i.e., URL of the web site).\n",
    "3. Load the Dataset into pandas dataframe.\n",
    "4. Data Preprocessing: check for missing values in the data using pandas isnull(), describe()\n",
    "function to get some initial statistics. Provide variable descriptions. Types of variables etc.\n",
    "Check the dimensions of the data frame.\n",
    "5. Data Formatting and Data Normalization: Summarize the types of variables by checking\n",
    "the data types (i.e., character, numeric, integer, factor, and logical) of the variables in the\n",
    "data set. If variables are not in the correct data type, apply proper type conversions.\n",
    "6. Turn categorical variables into quantitative variables in Python.\n",
    "In addition to the codes and outputs, explain every operation that you do in the above steps and\n",
    "explain everything that you do to import/read/scrape the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a098b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import all the required Python Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 2. Load the dataset into pandas dataframe\n",
    "# Replace with your local path or use online URL if you have one\n",
    "df = pd.read_csv(r\"E:\\DSBDAL\\1\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5e9c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# 3. Initial View of the Dataset\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de55efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing values:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "\n",
      "Dataset Description:\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n",
      "\n",
      "Variable Types:\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "Shape of the DataFrame:\n",
      "(418, 11)\n"
     ]
    }
   ],
   "source": [
    "# 4. Data Preprocessing\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDataset Description:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nVariable Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nShape of the DataFrame:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "370e531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after filling:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Data Formatting and Normalization\n",
    "# Convert object types if needed\n",
    "df['Sex'] = df['Sex'].astype('category')\n",
    "df['Embarked'] = df['Embarked'].astype('category')\n",
    "\n",
    "# Fill missing values\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "\n",
    "\n",
    "# Confirm again\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00d30668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types after conversion:\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Sex_male          bool\n",
      "Embarked_Q        bool\n",
      "Embarked_S        bool\n",
      "dtype: object\n",
      "\n",
      "Final DataFrame (first 5 rows):\n",
      "   PassengerId  Pclass                                          Name   Age  \\\n",
      "0          892       3                              Kelly, Mr. James  34.5   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  47.0   \n",
      "2          894       2                     Myles, Mr. Thomas Francis  62.0   \n",
      "3          895       3                              Wirz, Mr. Albert  27.0   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0   \n",
      "\n",
      "   SibSp  Parch   Ticket     Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \n",
      "0      0      0   330911   7.8292   NaN      True        True       False  \n",
      "1      1      0   363272   7.0000   NaN     False       False        True  \n",
      "2      0      0   240276   9.6875   NaN      True        True       False  \n",
      "3      0      0   315154   8.6625   NaN      True       False        True  \n",
      "4      1      1  3101298  12.2875   NaN     False       False        True  \n"
     ]
    }
   ],
   "source": [
    "# 6. Turning categorical variables into quantitative variables\n",
    "# Use one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    "\n",
    "# Final DataFrame overview\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nFinal DataFrame (first 5 rows):\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b45d52",
   "metadata": {},
   "source": [
    "Here's the **theory** (detailed explanation) for your practical on **Data Wrangling - I** using Python and Pandas:\n",
    "Practical: Data Wrangling - I (Using Python)\n",
    "Objective:\n",
    "To perform data wrangling operations on an open-source dataset by importing, cleaning, formatting, and transforming the data using Python libraries such as Pandas and NumPy.\n",
    "1.Importing Required Python Libraries:\n",
    "python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "**Pandas:** Used for data manipulation and analysis. The `DataFrame` structure it provides makes it easy to handle tabular data.\n",
    "-**NumPy:** A library for numerical operations and handling arrays efficiently. It is often used for mathematical operations and working with missing values.\n",
    "2. Dataset Source and Description:**\n",
    "**Dataset Used:** Titanic dataset (commonly used for machine learning and data preprocessing practice).\n",
    "Source:** [Kaggle - Titanic: Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic/data)\n",
    "Description:** The dataset contains information about passengers on the Titanic, such as age, gender, class, survival status, and boarding details.\n",
    "File Used:** `test.csv`\n",
    "3. Loading the Dataset:**\n",
    "python\n",
    "df = pd.read_csv(r\"E:\\DSBDAL\\1\\test.csv\")\n",
    "The dataset is read using `pd.read_csv()`, and the contents are loaded into a DataFrame.\n",
    "- An initial look at the data is given using:\n",
    "  ```python\n",
    "  print(df.head())\n",
    "4. Data Preprocessing:**\n",
    "a) Checking for Missing Values:\n",
    "```python\n",
    "print(df.isnull().sum())\n",
    "This shows how many null values exist in each column.\n",
    "b) Descriptive Statistics:\n",
    "python\n",
    "print(df.describe())\n",
    "Provides summary statistics such as count, mean, standard deviation, min, and max for numeric columns.\n",
    "c) Data Types and Dimensions:\n",
    "```python\n",
    "print(df.dtypes)\n",
    "print(df.shape)\n",
    "Helps identify types of each variable (e.g., `int64`, `object`, `float64`) and shape of the dataset (rows × columns).\n",
    "5. Data Formatting and Normalization:**\n",
    "a) Data Type Conversion:\n",
    "```python\n",
    "df['Sex'] = df['Sex'].astype('category')\n",
    "df['Embarked'] = df['Embarked'].astype('category')\n",
    "Converting object-type categorical variables into `category` improves memory usage and analysis.\n",
    "b) Handling Missing Values:\n",
    "```python\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df['Embarked'] = df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "- Missing `Age` values are filled with the column’s mean.\n",
    "- Missing `Embarked` values are filled with the most frequent value (mode).\n",
    "6. Encoding Categorical Variables:**\n",
    "\n",
    "```python\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)\n",
    " Converts categorical variables into numeric form using **one-hot encoding**.\n",
    "- `drop_first=True` avoids multicollinearity by removing one of the dummy columns.\n",
    "**Conclusion:**\n",
    "\n",
    "- Data wrangling involves steps like importing data, identifying missing values, converting data types, and encoding categorical variables.\n",
    "- After this process, the dataset becomes clean, consistent, and ready for data analysis or machine learning tasks.\n",
    "Learning Outcomes:**\n",
    "- Ability to load and inspect a real-world dataset.\n",
    "- Familiarity with common preprocessing techniques like handling missing data and encoding.\n",
    "- Understanding of data types and proper data formatting practices."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
